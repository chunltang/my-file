*********************总结（https://my.oschina.net/u/3847203/blog/2878112）*********************
===============================================================================================

1.它是一个针对大型分布式系统的可靠协调系统，它主要是用来解决分布式应用中经常遇到的一些数据管理问题，
可以高可靠的维护元数据。提供的功能包括：配置维护、名字服务、分布式同步、组服务等。
ZooKeeper的设计目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。

2.Zookeeper 作为一个分布式的服务框架，主要用来解决分布式集群中应用系统的一致性问题，它能提供基于类似于文件系统的目录节点树方式的数据存储，
但是 Zookeeper 并不是用来专门存储数据的，它的作用主要是用来维护和监控你存储的数据的状态变化。通过监控这些数据状态的变化，从而可以达到基于数据的集群管理

3.集群管理：利用临时节点特性，节点关联的是机器的主机名、IP地址等相关信息，集群单点故障也属于该范畴。
　统一命名：主要利用节点的唯一性和目录节点树结构。
　配置管理：节点关联的是配置信息。
　分布式锁：节点关联的是要竞争的资源。

4.ZooKeeper是一个高可用的分布式数据管理与系统协调框架。基于对Paxos算法的实现，使该框架保证了分布式环境中数据的强一致性，也正是基于这样的特性，使得zookeeper能够应用于很多场景


*****************************************************************************************************************************

5.典型场景描述 (https://www.cnblogs.com/sunddenly/p/4092654.html)

(1).发布与订阅
即所谓的配置管理，顾名思义就是将数据发布到ZK节点上，供订阅者动态获取数据，实现配置信息的集中式管理和动态更新。
例如全局的配置信息，地址列表等就非常适合使用。集中式的配置管理在应用集群中是非常常见的，一般商业公司内部都会实现一套集中的配置管理中心，
应对不同的应用集群对于共享各自配置的需求，并且在配置变更时能够通知到集群中的每一个机器

(2).统一命名服务（Name Service）
分布式应用中，通常需要有一套完整的命名规则，既能够产生唯一的名称又便于人识别和记住，通常情况下用树形的名称结构是一个理想的选择，
树形的名称结构是一个有层次的目录结构，既对人友好又不会重复。说到这里你可能想到了 JNDI，没错 Zookeeper 的 Name Service 与 JNDI 能够完成的功能是差不多的，
它们都是将有层次的目录结构关联到一定资源上，但是Zookeeper的Name Service 更加是广泛意义上的关联，也许你并不需要将名称关联到特定资源上，
你可能只需要一个不会重复名称，就像数据库中产生一个唯一的数字主键一样

(3).分布通知/协调（Distribution of notification/coordination）
ZooKeeper中特有watcher注册与异步通知机制，能够很好的实现分布式环境下不同系统之间的通知与协调，实现对数据变更的实时处理。
使用方法通常是不同系统都对ZK上同一个znode进行注册，监听znode的变化（包括znode本身内容及子节点的），其中一个系统update了znode，那么另一个系统能够收到通知，并作出相应处理。
应用:
① 另一种心跳检测机制：检测系统和被检测系统之间并不直接关联起来，而是通过ZK上某个节点关联，大大减少系统耦合。
② 另一种系统调度模式：某系统由控制台和推送系统两部分组成，控制台的职责是控制推送系统进行相应的推送工作。管理人员在控制台作的一些操作，实际上是修改了ZK上某些节点的状态，而ZK就把这些变化通知给他们注册Watcher的客户端，即推送系统，于是，作出相应的推送任务。
③ 另一种工作汇报模式：一些类似于任务分发系统，子任务启动后，到ZK来注册一个临时节点，并且定时将自己的进度进行汇报（将进度写回这个临时节点），这样任务管理者就能够实时知道任务进度。
总之，使用zookeeper来进行分布式通知和协调能够大大降低系统之间的耦合。

(4).分布式锁（Distribute Lock）
分布式锁，这个主要得益于ZooKeeper为我们保证了数据的强一致性，即用户只要完全相信每时每刻，zk集群中任意节点（一个zk server）上的相同znode的数据是一定是相同的。
锁服务可以分为两类，一个是保持独占，另一个是控制时序。
保持独占:
就是所有试图来获取这个锁的客户端，最终只有一个可以成功获得这把锁。通常的做法是把ZK上的一个znode看作是一把锁，通过create znode的方式来实现。
所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。
控制时序:
就是所有试图来获取这个锁的客户端，最终都是会被安排执行，只是有个全局时序了。做法和上面基本类似，只是这里 /distribute_lock 已经预先存在，
客户端在它下面创建临时有序节点。Zk的父节点（/distribute_lock）维持一份sequence,保证子节点创建的时序性，从而也形成了每个客户端的全局时序。

应用 :
共享锁在同一个进程中很容易实现，但是在跨进程或者在不同 Server 之间就不好实现了。Zookeeper 却很容易实现这个功能，
实现方式也是需要获得锁的 Server 创建一个 EPHEMERAL_SEQUENTIAL 目录节点，然后调用 getChildren方法获取当前的目录节点列表中最小的目录节点是不是就是自己创建的目录节点，
如果正是自己创建的，那么它就获得了这个锁，如果不是那么它就调用 exists(String path, boolean watch) 方法并监控 Zookeeper 上目录节点列表的变化，
一直到自己创建的节点是列表中最小编号的目录节点，从而获得锁，释放锁很简单，只要删除前面它自己所创建的目录节点就行了

(5).集群管理（Cluster Management）
集群机器监控：
这通常用于那种对集群中机器状态，机器在线率有较高要求的场景，能够快速对集群中机器变化作出响应。这样的场景中，往往有一个监控系统，实时检测集群机器是否存活。
过去的做法通常是：监控系统通过某种手段（比如ping）定时检测每个机器，或者每个机器自己定时向监控系统汇报"我还活着"。 这种做法可行，但是存在两个比较明显的问题：
① 集群中机器有变动的时候，牵连修改的东西比较多。
② 有一定的延时。
利用ZooKeeper中两个特性，就可以实施另一种集群机器存活性监控系统：
① 客户端在节点 x 上注册一个Watcher，那么如果 x 的子节点变化了，会通知该客户端。
② 创建EPHEMERAL类型的节点，一旦客户端和服务器的会话结束或过期，那么该节点就会消失。

Master选举： 
Master选举则是zookeeper中最为经典的使用场景了，在分布式环境中，相同的业务应用分布在不同的机器上，有些业务逻辑，
例如一些耗时的计算，网络I/O处，往往只需要让整个集群中的某一台机器进行执行，其余机器可以共享这个结果，这样可以大大减少重复劳动，提高性能，
于是这个master选举便是这种场景下的碰到的主要问题。
利用ZooKeeper中两个特性，就可以实施另一种集群中Master选举：
① 利用ZooKeeper的强一致性，能够保证在分布式高并发情况下节点创建的全局唯一性，即：同时有多个客户端请求创建 /Master 节点，
最终一定只有一个客户端请求能够创建成功。利用这个特性，就能很轻易的在分布式环境中进行集群选举了。
②另外，这种场景演化一下，就是动态Master选举。这就要用到 EPHEMERAL_SEQUENTIAL类型节点的特性了，这样每个节点会自动被编号。
允许所有请求都能够创建成功，但是得有个创建顺序，每次选取序列号最小的那个机器作为Master 。

Master选举： 
Zookeeper 不仅能够维护当前的集群中机器的服务状态，而且能够选出一个"总管"，让这个总管来管理集群，这就是 Zookeeper 的另一个功能 Leader Election。
Zookeeper 如何实现 Leader Election，也就是选出一个 Master Server。和前面的一样每台 Server 创建一个 EPHEMERAL 目录节点，不同的是它还是一个 SEQUENTIAL 目录节点，
所以它是个 EPHEMERAL_SEQUENTIAL 目录节点。之所以它是 EPHEMERAL_SEQUENTIAL 目录节点，是因为我们可以给每台 Server 编号，我们可以选择当前是最小编号的 Server 为 Master，
假如这个最小编号的 Server 死去，由于是 EPHEMERAL 节点，死去的 Server 对应的节点也被删除，所以当前的节点列表中又出现一个最小编号的节点，我们就选择这个节点为当前 Master。
这样就实现了动态选择 Master，避免了传统意义上单 Master 容易出现单点故障的问题。

(6).队列管理
Zookeeper 可以处理两种类型的队列：
① 当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达，这种是同步队列。
② 队列按照 FIFO 方式进行入队和出队操作，例如实现生产者和消费者模型。
(1) 同步队列用 Zookeeper 实现的实现思路如下：
创建一个父目录 /synchronizing，每个成员都监控标志（Set Watch）位目录 /synchronizing/start 是否存在，然后每个成员都加入这个队列，
加入队列的方式就是创建 /synchronizing/member_i 的临时目录节点，然后每个成员获取 / synchronizing 目录的所有目录节点，也就是 member_i。
判断 i 的值是否已经是成员的个数，如果小于成员个数等待 /synchronizing/start 的出现，如果已经相等就创建 /synchronizing/start。
(2) FIFO 队列用 Zookeeper 实现思路如下：
实现的思路也非常简单，就是在特定的目录下创建 SEQUENTIAL 类型的子目录 /queue_i，这样就能保证所有成员加入队列时都是有编号的，
出队列时通过 getChildren( ) 方法可以返回当前所有的队列中的元素，然后消费其中最小的一个，这样就能保证 FIFO。

*****************************************************************************************************************************

6.权限管理ACL(Access Control List)　(https://www.cnblogs.com/sunddenly/p/4133784.html)

ZooKeeper 的权限管理亦即ACL 控制功能，使用ACL来对Znode进行访问控制。
ACL的实现和Unix文件访问许可非常相似：它使用许可位来对一个节点的不同操作进行允许或禁止的权限控制。
但是和标准的Unix许可不同的是，Zookeeper对于用户类别的区分，不止局限于所有者(owner)、组 (group)、所有人(world)三个级别。Zookeeper中，
数据节点没有"所有者"的概念。访问者利用id标识自己的身份，并获得与之相应的不同的访问权限。
ZooKeeper 的权限管理通过Server、Client 两端协调完成.

注意的是，exists操作和getAcl操作并不受ACL许可控制，因此任何客户端可以查询节点的状态和节点的ACL。

*****************************************************************************************************************************

7. Watch机制 (https://www.cnblogs.com/sunddenly/p/4133784.html)

Zookeeper客户端在数据节点上设置监视，则当数据节点发生变化时，客户端会收到提醒。
ZooKeeper中的各种读请求，如getDate()，getChildren()，和exists()，都可以选择加"监视点"(watch)。
"监视点"指的是一种一次性的触发器(trigger)，当受监视的数据发生变化时，该触发器会通知客户端。 

*****************************************************************************************************************************

8.ZooKeeper的CAP理论 (https://www.cnblogs.com/sunddenly/p/4138580.html)

ZooKeeper的保证
经过上面的分析，我们知道要保证ZooKeeper服务的高可用性就需要采用分布式模式，来冗余数据写多份，写多份带来一致性问题，
一致性问题又会带来性能问题，那么就此陷入了无解的死循环。那么在这，就涉及到了我们分布式领域的著名的CAP理论，在这就简单的给大家介绍一下，关于CAP的详细内容大家可以网上查阅。

CAP理论
(1) 理论概述 
分布式领域中存在CAP理论：
① C：Consistency，一致性，数据一致更新，所有数据变动都是同步的。
② A：Availability，可用性，系统具有好的响应性能。
③ P：Partition tolerance，分区容错性。以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，
必须就当前操作在C和A之间做出选择，也就是说无论任何消息丢失，系统都可用。
该理论已被证明：任何分布式系统只可同时满足两点，无法三者兼顾。 因此，将精力浪费在思考如何设计能满足三者的完美系统上是愚钝的，应该根据应用场景进行适当取舍。
(2) 一致性分类
一致性是指从系统外部读取系统内部的数据时，在一定约束条件下相同，即数据变动在系统内部各节点应该是同步的。根据一致性的强弱程度不同，可以将一致性级别分为如下几种：
① 强一致性（strong consistency）。任何时刻，任何用户都能读取到最近一次成功更新的数据。
② 单调一致性（monotonic consistency）。任何时刻，任何用户一旦读到某个数据在某次更新后的值，那么就不会再读到比这个值更旧的值。也就是说，可获取的数据顺序必是单调递增的。
③ 会话一致性（session consistency）。任何用户在某次会话中，一旦读到某个数据在某次更新后的值，那么在本次会话中就不会再读到比这个值更旧的值。
会话一致性是在单调一致性的基础上进一步放松约束，只保证单个用户单个会话内的单调性，在不同用户或同一用户不同会话间则没有保障。
④ 最终一致性（eventual consistency）。用户只能读到某次更新后的值，但系统保证数据将最终达到完全一致的状态，只是所需时间不能保障。
⑤ 弱一致性（weak consistency）。用户无法在确定时间内读到最新更新的值。

ZooKeeper与CAP理论：
我们知道ZooKeeper也是一种分布式系统，它在一致性上有人认为它提供的是一种强一致性的服务（通过sync操作），也有人认为是单调一致性（更新时的大多说概念），
还有人为是最终一致性（顺序一致性），反正各有各的道理这里就不在争辩了。然后它在分区容错性和可用性上做了一定折中，这和CAP理论是吻合的。ZooKeeper从以下几点保证了数据的一致性
① 顺序一致性 
来自任意特定客户端的更新都会按其发送顺序被提交。也就是说，如果一个客户端将Znode z的值更新为a，在之后的操作中，它又将z的值更新为b，
则没有客户端能够在看到z的值是b之后再看到值a（如果没有其他对z的更新）。
② 原子性 
每个更新要么成功，要么失败。这意味着如果一个更新失败，则不会有客户端会看到这个更新的结果。
③ 单一系统映像 
一个客户端无论连接到哪一台服务器，它看到的都是同样的系统视图。这意味着，如果一个客户端在同一个会话中连接到一台新的服务器，
它所看到的系统状态不会比在之前服务器上所看到的更老。当一台服务器出现故障，导致它的一个客户端需要尝试连接集合体中其他的服务器时，
所有滞后于故障服务器的服务器都不会接受该连接请求，除非这些服务器赶上故障服务器。
④ 持久性 
一个更新一旦成功，其结果就会持久存在并且不会被撤销。这表明更新不会受到服务器故障的影响。


*****************************************************************************************************************************

9.数据一致性：(https://www.cnblogs.com/sunddenly/p/4138580.html)
ZK集群中每个Server，都保存一份数据副本。Zookeeper使用简单的同步策略，通过以下两条基本保证来实现数据的一致性：
① 全局串行化所有的写操作
② 保证同一客户端的指令被FIFO执行（以及消息通知的FIFO）
所有的读请求由Zk Server 本地响应，所有的更新请求将转发给Leader，由Leader实施。

zab协议：
有两种工作模式：恢复模式、广播模式
恢复模式用来进行leader选举
广播模式用来实现数据一致性，类似两阶段提交，leader发起一个提议，收集follower选票，follower收到请求后并执行持久化操作，当leader收到
通过提议的机器数超过半数时，leader本身完成commit提交。当收到Leader发来commit消息时，Follower也会递交该消息。在leader在发出消息之前，会给消息生成一个单调单调递增的id，称为zxid，
当leader挂掉重新选举后，新leader会从所有follower中获取拥有最大的zxid的follower，来获取丢失事务(事务日志)。

客户端和服务器使用NIO通信，leader和follower使用TCP/IP通信

zookeeper的三种角色：(https://www.cnblogs.com/sunddenly/p/4143306.html)
Leader、Follower、Observer(不参与选举)
leader角色两个任务： 
事务请求的唯一调度者和处理者，保证集群事务处理的顺序性
集群内部各个服务器的调度者
Follower 角色任务 
处理客户端非事务请求，转发事务请求给leader
参与leader发起的事务提交投票，超过半数统一leader才能commit
observer角色任务 
ZooKeeper3.3引进的
观察ZooKeeper集群最新变化状态，并且同步套自己服务器上
不参与一切投票：包括事务投票和leader选举
仅仅提供非事务服务，在不影响集群事务处理能力的前提下，提升非事务处理能力

在ZooKeeper中引入Observer，主要是为了使ZooKeeper具有更好的可伸缩性，如果我们的工作负载可以通过给系统分配更多的资源来分担，
那么这个系统就是可伸缩的；一个不可伸缩的系统却无法通过增加资源来提升性能，甚至会在工作负载增加时，性能会急剧下降。

Zab协议规定：来自Client的所有写请求，都要转发给ZK服务中唯一的Server—Leader，由Leader根据该请求发起一个Proposal。
然后，其他的Server对该Proposal进行Vote。之后，Leader对Vote进行收集，当Vote数量过半时Leader会向所有的Server发送一个通知消息。
最后，当Client所连接的Server收到该消息时，会把该操作更新到内存中并对Client的写请求做出回应。

在增加Client数量的期望和我们希望保持较好吞吐性能的期望间进行权衡。要打破这一耦合关系，我们引入了不参与投票的服务器，称为 Observer。
Observer可以接受客户端的连接，并将写请求转发给Leader节点。
但是，Leader节点不会要求 Observer参加投票。相反，Observer不参与投票过程，仅仅在上述第3歩那样，和其他服务节点一起得到投票结果.
Observer提升读性能的可伸缩性


自己总结有问题(看https://my.oschina.net/u/3847203/blog/2878112)
leader选举：
每个server在加入集群时，都会生成一个单调递增的编号，每个server都保存小于自身的最大编号，拥有最小编号的server称为leader，当leader奔溃后，其他server收到通知，存活的server中拥有最小编号
的server成为新的leader

新leader恢复数据：
集群中的每个写操作都是一个事务，每个事务都有唯一编号(zxid)，为64，搞32为当前leader实列的编号，底32为当前leader实列执行的事务次数，当新leader选举成功后，会在集群中获取最高编号的事务。
事务请求都有leader统一处理，保证集群事务处理的顺序性

